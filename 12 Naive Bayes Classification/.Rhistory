messages <- read.csv(file.choose())
messages
View(messages)
library(dplyr)
messages %>%
filter(type == "ham") %>%
select(nrow(messages))
messages %>%
filter(type == "ham") %>%
select(nrow(messages$text))
messages %>%
filter(type == "spam") %>%
select(nrow(messages$text))
prop.table(table(messages$type))
library(tm)
# converting a
str(sms_raw$text)
# converting a
str(sms_raw$text)
# converting a
str(messages$text)
messages_corpus <- Corpus(VectorSource(messages$text))
View(messages_corpus)
View(messages_corpus)
View(messages_corpus)
messages_corpus <- tm_map(messages_corpus, function(x) iconv(enc2utf8(x), sub='byte'))
messages_corpus
View(messages_corpus)
View(messages_corpus)
str(messages_corpus)
class(messages_corpus)
corpus_clean <- tm_map(messages_corpus, tolower)
corpus_clean <- tm_map(corpus_clean, removePunctuation)
corpus_clean <- tm_map(corpus_clean, removeNumbers)
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, stripWhitespace)
View(corpus_clean)
msg_dtm <- DocumentTermMatrix(corpus_clean)
View(msg_dtm)
View(msg_dtm)
View(msg_dtm[1:10, 1:30])
msg_dtm[1:10, 1:30][["dimnames"]][["Terms"]]
msg_dtm[1:10, 1:30][["dimnames"]][["Terms"]]
gsub('[^A-Za-z" "]+', '', msg_dtm)
msg_dtm[1:10, 1:30][["dimnames"]][["Terms"]]
library(readr)
library(dplyr)
library(tm)
messages <- read.csv(file.choose())
View(messages)
messages %>%
filter(type == "ham") %>%
select(nrow(messages$text))
# data frame with 0 columns and 4812 rows in ham
messages %>%
filter(type == "spam") %>%
select(nrow(messages$text))
#data frame with 0 columns and 747 rows in spam
prop.table(table(messages$type))
# 86% ham and 13% spam in messages data
# converting a character to > corpus
str(messages$text)
messages_corpus <- Corpus(VectorSource(messages$text))
View(messages_corpus)
messages_corpus <- tm_map(messages_corpus, function(x) iconv(enc2utf8(x), sub='byte'))
str(messages_corpus)
class(messages_corpus)
### Data Cleaning ###
corpus_clean <- tm_map(messages_corpus, tolower)
corpus_clean <- tm_map(corpus_clean, removePunctuation)
corpus_clean <- tm_map(corpus_clean, removeNumbers)
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, stripWhitespace)
msg_dtm[1:10, 1:30][["dimnames"]][["Terms"]]
View(corpus_clean)
msg_dtm <- DocumentTermMatrix(corpus_clean)
View(msg_dtm[1:10, 1:30])
msg_dtm[1:10, 1:30][["dimnames"]][["Terms"]]
msg_dtm[22:,:][["dimnames"]][["Terms"]]
msg_dtm[22:,:][["dimnames"]][["Terms"]]
msg_dtm[22:,][["dimnames"]][["Terms"]]
msg_dtm[22:][["dimnames"]][["Terms"]]
colnames(msg_dtm)[1:50]
corpus_clean <- tm_map(corpus_clean, removeWords, c('\xe3�\xe2�'))
colnames(msg_dtm)[1:50]
install.packages(catTools)
install.packages(caTools)
install.packages("caTools")
sample <- sample.int(n = nrow(msg_dtm), size = floor(.75*nrow(msg_dtm)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]
train.shape
train <- data[sample, ]
sample <- sample(n = nrow(msg_dtm), size = floor(.75*nrow(msg_dtm)), replace = F)
sample <- sample(size = floor(.75*nrow(msg_dtm)), replace = F)
######## spitting the data on train and test
set.seed(101)
library(ISLR)
install.packages("ISLR")
library(ISLR)
attach(msg_tdm)
attach(msg_dtm)
smp_siz = floor(0.75*nrow(msg_dtm))
smp_siz
# for dtm data
train_dtm <- msg_dtm[sample,]
test_dtm <- msg_dtm[-sample,]
#for corpus dataset
train_corpus <- corpus_clean[sample,]
#for corpus dataset
sample = sample(seq_len(nrow(corpus_clean)),size = smp_siz)
#for corpus dataset
train_corpus <- corpus_clean[sample,]
#for corpus dataset
sms_corpus_train <- corpus_clean[1:4169]
sms_corpus_test  <- corpus_clean[4170:5559]
#for original messages dataset
messages_train <- messages[1:4169, ]
messages_test  <- messages[4170:5559, ]
### train on the model using NB
library(e1071)
prop.table(table(messages$type))
prop.table(table(messages_train$type))
prop.table(table(messages_test$type))
sms_classifier <- naiveBayes(train_dtm, messages$type)
# indicator features for frequent words
# dictionary of words which are used more than 5 times
sms_dict <- findFreqTerms(train_dtm, 5)
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary = sms_dict))
sms_test  <- DocumentTermMatrix(sms_corpus_test, list(dictionary = sms_dict))
sms_test_matrix <- as.matrix(sms_test)
View(sms_test_matrix[1:10,1:10])
View(sms_test_matrix[1:10,1:10])
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
}
sms_train <- apply(sms_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_test, MARGIN = 2, convert_counts)
?apply()
View(sms_test[1:10,1:10])
sms_classifier <- naiveBayes(sms_train, messages$type)
sms_classifier
# for dtm data
train_dtm <- msg_dtm[1:4169]
test_dtm <- msg_dtm[4170:5559]
# for dtm data
train_dtm <- msg_dtm[1:4169,]
test_dtm <- msg_dtm[4170:5559,]
#for corpus dataset
sms_corpus_train <- corpus_clean[1:4169,]
#for corpus dataset
sms_corpus_train <- corpus_clean[1:4169,]
#for corpus dataset
sms_corpus_train <- corpus_clean[1:4169]
sms_corpus_test  <- corpus_clean[4170:5559]
#for original messages dataset
messages_train <- messages[1:4169, ]
messages_test  <- messages[4170:5559, ]
prop.table(table(messages$type))
prop.table(table(messages_train$type))
prop.table(table(messages_test$type))
# indicator features for frequent words
# dictionary of words which are used more than 5 times
sms_dict <- findFreqTerms(train_dtm, 5)
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary = sms_dict))
sms_test  <- DocumentTermMatrix(sms_corpus_test, list(dictionary = sms_dict))
sms_test_matrix <- as.matrix(sms_test)
View(sms_test_matrix[1:10,1:10])
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
}
sms_train <- apply(sms_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_test, MARGIN = 2, convert_counts)
?apply()
sms_classifier <- naiveBayes(sms_train, messages$type)
sms_classifier
sms_classifier <- naiveBayes(sms_train, messages$type)
# Import the raw_sms dataset
library(readr)
sms_raw <-read.csv(file.choose())
str(sms_raw)
sms_raw$type <- factor(sms_raw$type)
# examine the type variable more carefully
str(sms_raw$type)
table(sms_raw$type)
# proportion of ham and spam messages
prop.table(table(sms_raw$type))
# build a corpus using the text mining (tm) package
install.packages("tm")
install.packages("tm")
# proportion of ham and spam messages
prop.table(table(sms_raw$type))
# build a corpus using the text mining (tm) package
install.packages("tm")
library(tm)
str(sms_raw$text)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
sms_corpus <- tm_map(sms_corpus, function(x) iconv(enc2utf8(x), sub='byte'))
# clean up the corpus using tm_map()
corpus_clean <- tm_map(sms_corpus, tolower)
corpus_clean <- tm_map(corpus_clean, removePunctuation)
corpus_clean <- tm_map(corpus_clean, removeNumbers)
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, stripWhitespace)
# create a document-term sparse matrix
sms_dtm <- DocumentTermMatrix(corpus_clean)
sms_dtm
View(sms_dtm[1:10, 1:30])
# To view DTM we need to convert it into matrix first
dtm_matrix <- as.matrix(sms_dtm)
str(dtm_matrix)
View(dtm_matrix[1:10, 1:20])
colnames(sms_dtm)[1:50]
# creating training and test datasets
sms_raw_train <- sms_raw[1:4169, ]
sms_raw_test  <- sms_raw[4170:5559, ]
sms_corpus_train <- corpus_clean[1:4169]
sms_corpus_test  <- corpus_clean[4170:5559]
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]
# check that the proportion of spam is similar
prop.table(table(sms_raw$type))
prop.table(table(sms_raw_train$type))
prop.table(table(sms_raw_test$type))
# indicator features for frequent words
# dictionary of words which are used more than 5 times
sms_dict <- findFreqTerms(sms_dtm_train, 5)
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary = sms_dict))
sms_test  <- DocumentTermMatrix(sms_corpus_test, list(dictionary = sms_dict))
sms_test_matrix <- as.matrix(sms_test)
View(sms_test_matrix[1:10,1:10])
# convert counts to a factor
# custom function: if a word is used more than 0 times then mention 1 else mention 0
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
}
# apply() convert_counts() to columns of train/test data
# Margin = 2 is for columns
# Margin = 1 is for rows
sms_train <- apply(sms_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_test, MARGIN = 2, convert_counts)
?apply()
View(sms_test[1:10,1:10])
##  Training a model on the data ----
install.packages("e1071")
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
sms_classifier
##  Evaluating model performance
sms_test_pred <- predict(sms_classifier, sms_test)
library(gmodels)
CrossTable(sms_test_pred, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# On Training Data
sms_train_pred <- predict(sms_classifier, sms_train)
train_acc = mean(sms_train_pred == sms_raw_train$type)
train_acc
library(readr)
library(dplyr)
library(tm)
install.packages("caTools")
messages <- read.csv(file.choose())
View(messages)
messages %>%
filter(type == "ham") %>%
select(nrow(messages$text))
messages %>%
filter(type == "spam") %>%
select(nrow(messages$text))
prop.table(table(messages$type))
messages_corpus <- Corpus(VectorSource(messages$text))
View(messages_corpus)
messages_corpus <- tm_map(messages_corpus, function(x) iconv(enc2utf8(x), sub='byte'))
str(messages_corpus)
class(messages_corpus)
### Data Cleaning ###
corpus_clean <- tm_map(messages_corpus, tolower)
corpus_clean <- tm_map(corpus_clean, removePunctuation)
corpus_clean <- tm_map(corpus_clean, removeNumbers)
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, stripWhitespace)
# create a document-term sparse matrix
sms_dtm <- DocumentTermMatrix(corpus_clean)
sms_dtm
View(sms_dtm[1:10, 1:30])
# To view DTM we need to convert it into matrix first
dtm_matrix <- as.matrix(sms_dtm)
str(dtm_matrix)
View(dtm_matrix[1:10, 1:20])
# To view DTM we need to convert it into matrix first
dtm_matrix <- as.matrix(sms_dtm)
str(dtm_matrix)
View(dtm_matrix[1:10, 1:20])
colnames(sms_dtm)[1:50]
# creating training and test datasets
sms_raw_train <- messages[1:4169, ]
sms_raw_test  <- messages[4170:5559, ]
sms_corpus_train <- corpus_clean[1:4169]
sms_corpus_test  <- corpus_clean[4170:5559]
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]
# check that the proportion of spam is similar
prop.table(table(sms_raw$type))
prop.table(table(sms_raw_train$type))
prop.table(table(sms_raw_test$type))
# indicator features for frequent words
# dictionary of words which are used more than 5 times
sms_dict <- findFreqTerms(sms_dtm_train, 5)
sms_train <- DocumentTermMatrix(sms_corpus_train, list(dictionary = sms_dict))
sms_test  <- DocumentTermMatrix(sms_corpus_test, list(dictionary = sms_dict))
sms_test_matrix <- as.matrix(sms_test)
View(sms_test_matrix[1:10,1:10])
# convert counts to a factor
# custom function: if a word is used more than 0 times then mention 1 else mention 0
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
}
# apply() convert_counts() to columns of train/test data
# Margin = 2 is for columns
# Margin = 1 is for rows
sms_train <- apply(sms_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_test, MARGIN = 2, convert_counts)
?apply()
View(sms_test[1:10,1:10])
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_raw_train$type)
sms_classifier
##  Evaluating model performance
sms_test_pred <- predict(sms_classifier, sms_test)
library(gmodels)
CrossTable(sms_test_pred, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
test_acc = mean(sms_test_pred == sms_raw_test$type)
test_acc
CrossTable(sms_test_pred, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
CrossTable(sms_test_pred, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
##  Evaluating model performance
sms_test_pred <- predict(sms_classifier, sms_test)
library(gmodels)
CrossTable(sms_test_pred, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
sms_raw_test$type
sms_test_pred
sms_test_pred
sms_raw_test$type
sms_test_pred
sms_test_pred
