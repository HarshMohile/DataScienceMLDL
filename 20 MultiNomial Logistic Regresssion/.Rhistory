require('mlogit')
require('nnet')
library(readr)
st <- read.csv(file.choose())
View(st)
View(st)
View(st)
View(st)
st <- st[,c(-1,-2)]
View(st)
View(st)
# Data cleaning
sum(is.na(st1))
# Data cleaning
sum(is.na(st))
# rename the female col to gender
colnames(st1$female) <- "gender"
# rename the female col to gender
colnames(st$female) <- "gender"
library(dplyr)
st %>%
rename(
female = gender
)
View(st)
View(st)
st %>%
rename(
gender = female
)
View(st)
View(st)
# rename the female col to gender
names(st)[names(st) == "female"] <- "gender"
View(st)
View(st)
# Factor the categorical variables
st$gender <- as.factor(st$gender)
st$ses <- as.factor(st$ses)
st$schtyp <- as.factor(st$schtyp)
st$honors <- as.factor(st$honors)
library(caTools)
set.seed(0)
split <- sample.split(st$prog, SplitRatio = 0.8)# --------- both are X_train , X_test
train <- subset(st, split == TRUE)
test <- subset(st, split == FALSE)
st_model <- multinom(prog ~ ., data = train)
summary(st_model)
View(st)
View(st)
View(st)
View(st)
# academic to be baseline in this case
st$prog  <- relevel(st$prog, ref= "academic")
##### Significance of Regression Coefficients###
z <- summary(st_model)$coefficients / summary(st_model)$standard.errors
z
p_value <- (1 - pnorm(abs(z), 0, 1)) * 2
p_value
p_value
# odds ratio
exp(coef(st_model))
# check for fitted values on training data
prob <- fitted(st_model)
View(prob)
View(prob)
View(prob)
View(prob)
# check for fitted values on training data (Creates seperate col for each category present in y)
# academic , general , vocation
?fitted
# Predicted on test data
pred_test <- predict(st_model, newdata =  test, type = "probs") # type="probs" is to calculate probabilities
pred_test
# Find the accuracy of the model
class(pred_test)
pred_test <- data.frame(pred_test)
pred_test["prediction"] <- NULL
View(pred_test)
View(pred_test)
View(pred_test)
?apply
pred_test$prediction
get_names <- function(i){
return (names(which.max(i)))
}
predtest_name <- apply(pred_test, 1, get_names)
pred_test$prediction <- predtest_name
View(pred_test)
pred_test
# Confusion matrix
table(predtest_name, test$prog)
barplot(table(predtest_name, test$prog),
beside = T, col =c("red", "lightgreen", "blue", "orange"),
main = "Predicted(X-axis) - Legends(Actual)",
ylab ="count")
# Accuracy on test data
mean(predtest_name == test$choice)
# Accuracy on test data
mean(predtest_name == test$prog)
##############################################################
#training data
pred_train <- multinom(prog ~ . newdata= train ,type="probs")
##############################################################
#training data
pred_train <- multinom(prog ~ ., newdata= train ,type="probs")
##############################################################
#training data
pred_train <- multinom(prog ~ .,newdata= train ,type="probs")
##############################################################
#training data
############################################TRAINING DATA#########################################
#training data
pred_test <- predict(st_model, newdata =  test, type = "probs") # type="probs" is to calculate probabilities
############################################TRAINING DATA#########################################
#training data
pred_train <- predict(st_model, newdata =  train, type = "probs") # type="probs" is to calculate probabilities
pred_train
# Accuracy of the model
class(pred_train)
ped_traindf <- as.data.frame(pred_train)
pred_traindf <- as.data.frame(pred_train) # convert into df
pred_traindf["PREDICTIONS"] <- NULL
predtrain_name <- apply(pred_traindf, 1, get_names)
pred_traindf["PREDICTIONS"] <- predtest_name
View(pred_traindf)
# compare ped with actual
table(pred_traindf$PREDICTIONS , train$prog)
mean((pred_traindf$PREDICTIONS , train$prog)
mean(pred_traindf$PREDICTIONS , train$prog)
acc_train <- pred_traindf$PREDICTIONS == train$prog
acc_train
mean(acc_train)
#Plotting the confusion matrix
barplot(table(pred_traindf$PREDICTIONS , train$prog))
barplot(table(pred_traindf$PREDICTIONS , train$prog)
,beside=T)
barplot(table(pred_traindf$PREDICTIONS , train$prog)
,beside=T
,col =c("red", "lightgreen", "blue", "orange")
,main = "Predicted(X-axis) - Legends(Actual)"
, ylab ="count")
#Plotting the confusion matrix
barplot(table(pred_traindf$PREDICTIONS , train$prog)
,beside=T
,col =c("red", "lightgreen", "blue", "orange")
,main = "Predicted(X-axis) - Legends(Actual) Training data"
, ylab ="count")
