# -*- coding: utf-8 -*-
"""CIFAR10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x5rOadDfjJjpRXb4Xa1BTG0g_Ys6zIge
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from tensorflow.keras import datasets ,layers ,models
from tensorflow import keras

# Data loading
(X_train , y_train) ,(X_test, y_test) = datasets.cifar10.load_data()

X_train.shape
# train sameple :50k , each sample is 32 *32 , 3 is RGB channel


X_test.shape


plt.imshow(X_train[0]) # view images 

###################### reshapping
y_train[:5]
y_train.shape
y_train = y_train.reshape(-1,)

#Similarly for y_test
y_test[:5]
y_test= y_test.reshape(-1,)

# Scaling 0-255
X_train = X_train/255.0
X_test = X_test /255.0



#Sigmoid  gives probab as op  0.4 0.67  that added together doesnt equals 100 
# Softmax --- //  ---  0.45 0.59 such that  a+b =100  cuz a/a+b   b/a+b

def build_model(hp):  
  model = keras.Sequential([
                         
    keras.layers.Conv2D(
        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),
        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),
        activation='relu',
        input_shape=(32,32,3)
        
    ),
    keras.layers.MaxPooling2D((2,2)),

   
    keras.layers.Conv2D(
        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),
        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),
        activation='relu'
    ),
     keras.layers.MaxPooling2D((2,2)),
     
   
    keras.layers.Flatten(),
    keras.layers.Dense(
        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),
        activation='relu'
    ),
    keras.layers.Dense(10, activation='softmax')
  ])
  
  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
  
  return model

#!pip install keras-tuner

from kerastuner import RandomSearch
from kerastuner.engine.hyperparameters import HyperParameters

tuner=RandomSearch(build_model,
                          objective='val_accuracy',
                          max_trials=2,directory='output',project_name="CIFAR102")

# model.fit(X_Train ,y_train)
tuner.search(X_train,y_train,epochs=10,validation_split=0.2)

model=tuner.get_best_models(num_models=1)[0]

model.summary()

model.fit(X_train, y_train, epochs=10, validation_split=0.1)

model.evaluate(X_test,y_test)

#Predictions
y_pred = model.predict(X_test)
y_pred[:5]

#Comparing Actual and pred
y_classes = [np.argmax(element) for element in y_pred]
y_classes[:5]

y_test[:5]

# Plotting samples images to observe Actual to Pred

orig_classes = ["airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck"]

def plot_sample(X, y, index):
    plt.figure(figsize = (15,2))
    plt.imshow(X[index])
    plt.xlabel(orig_classes[y[index]])

plot_sample(X_train, y_train, 0)

# Actual
plot_sample(X_test, y_test, 3)

orig_classes[y_classes[3]]



